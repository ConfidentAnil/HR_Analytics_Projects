{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6f13e7",
   "metadata": {},
   "source": [
    "# Logistic Regression Handson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d33e99",
   "metadata": {},
   "source": [
    "Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c9d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab00aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data\n",
    "data = pd.read_csv('bank', sep=';')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1e467",
   "metadata": {},
   "source": [
    "Problem Statement : If the person is going to buy the insurance or not based on various features provided in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02885fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b64cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() #There are null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb09a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding outliers using boxplot\n",
    "cols = list(data.columns)\n",
    "for col in cols:\n",
    "    if data[col].dtype=='float64':\n",
    "        sns.boxplot(data[col])\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Count')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b422f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding outlier using upper fence and lower fence\n",
    "cols = ['age', 'duration', 'campaign', 'cons.conf.idx'] #List of columns to remove outliers of\n",
    "\n",
    "#Finding outlier and removing it for age column\n",
    "q1 = data.age.quantile(0.25)\n",
    "q3 = data.age.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "upper_fence = q3 + 1.5*iqr\n",
    "lower_fence = q1 - 1.5*iqr\n",
    "data = data[(data.age>lower_fence) & (data.age<upper_fence)]\n",
    "\n",
    "\n",
    "#plotting boxplot after removing outlier\n",
    "sns.boxplot(data.age)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d9be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding outlier and removing it for duration column\n",
    "q1 = data.duration.quantile(0.25)\n",
    "q3 = data.duration.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "upper_fence = q3 + 1.5*iqr\n",
    "lower_fence = q1 - 1.5*iqr\n",
    "data = data[(data.duration>lower_fence) & (data.duration<upper_fence)]\n",
    "\n",
    "\n",
    "\n",
    "#plotting boxplot after removing outlier\n",
    "sns.boxplot(data.duration)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d245d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding outlier and removing it for campaign column\n",
    "q1 = data.campaign.quantile(0.25)\n",
    "q3 = data.campaign.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "upper_fence = q3 + 1.5*iqr\n",
    "lower_fence = q1 - 1.5*iqr\n",
    "data = data[(data.campaign>lower_fence) & (data.campaign<upper_fence)]\n",
    "\n",
    "#plotting boxplot after removing outlier\n",
    "sns.boxplot(data.campaign)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44277ed",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking two categorical variables which we want to compare if they are related\n",
    "#First categorize both columns into grouping, for age column use pd.cut(), it takes bins parameter to group by certain range\n",
    "#Finding observed values using pd.crosstab function, it takes two columns as paramters\n",
    "#Finding expected value using chi2_contingency function and it takes observed value as input\n",
    "#Finding the chi square statistics, the formula is summation(o-e**2/e)\n",
    "#Finding degree of freedom, no.of.rows-1 * no.of.columns-1 of selected columns and rows only\n",
    "#Setting alpha value\n",
    "#Finding the critical value, it requires b\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Creating bins/grouping by for age column\n",
    "\n",
    "data['age'] = pd.cut(data['age'], bins = [0,50,100])\n",
    "data['age'] = data['age'].astype('str')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c240033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA - 83% of customers are in age group 0-50 and 16% in age group 50-100\n",
    "data.age.value_counts()/len(data.age)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fe6b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi-Square test : It checks if 2 categorical variables are related or not\n",
    "#We find the observed values and find the expected values and compare them and check if there is any depedency between them or not.\n",
    "\n",
    "#Forming Hypothesis\n",
    "#Null Hypothesis : Both variables are related\n",
    "#Alternate Hypothesis : Both variables are not related\n",
    "\n",
    "#importing libraries\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "\n",
    "#Creating contingency table for age and y column\n",
    "contingency_table = pd.crosstab(data['age'], data['y'])\n",
    "contingency_table\n",
    "#Inference from contingency table - \n",
    "''': People within age group 0-50 have people 26k not bought the insurance\n",
    ": People within age group 0-50 have people 2k bought the insurance\n",
    ": People within age group 50-100 have people 5k who not bought the insurance\n",
    ": People within age group 50-100 have people 0.5k who bought the insurance'''\n",
    "    \n",
    "\n",
    "\n",
    "#dataframe object method values will convert dataframe into array format\n",
    "observed_values = contingency_table.values\n",
    "#observed values\n",
    "observed_values\n",
    "\n",
    "\n",
    "#You get expected_frequency\n",
    "statistics = chi2_contingency(observed_values)\n",
    "expected_values = statistics[3]\n",
    "#expected values\n",
    "expected_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0776942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square = sum([(o-e)**2/e for o, e in zip(observed_values, expected_values)])\n",
    "\n",
    "chi_square\n",
    "chi_square[0] + chi_square[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fbe19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without for loop\n",
    "chi_square = np.sum(((observed_values - expected_values) ** 2) / expected_values)\n",
    "chi_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94102b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating chi-square contributions for each pair of observed and expected values\n",
    "chi_square_contributions = [(o - e) ** 2 / e for o, e in zip(observed_values.ravel(), expected_values.ravel())] #ravel method of array object will flatten or convert the array into 1D.\n",
    "\n",
    "# Sum up all the chi-square contributions to get the total chi-square statistic\n",
    "chi_square = np.sum(chi_square_contributions)\n",
    "\n",
    "print(chi_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82dd6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding degree of freedom\n",
    "num_of_rows = len(contingency_table.iloc[0:2,0])\n",
    "num_of_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3babba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding degree of freedom\n",
    "num_of_columns = len(contingency_table.iloc[:,0:])\n",
    "num_of_columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b86f6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree of freedom\n",
    "dof = (num_of_rows-1)*(num_of_columns-1)\n",
    "dof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ba8039",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94280034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding critical value\n",
    "critical_value = scipy.stats.chi2.ppf(1-alpha, df=dof)\n",
    "#Inverse cumulative distribution - critical value\n",
    "critical_value\n",
    "#We will compare the critical with chi square statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4485d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarizing hypothesis\n",
    "#if chi square statistics >= critical value -----> reject null hypothesis\n",
    "print(f'Chi Square Statistics : {chi_square}\\nCritical Value {critical_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562df54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding pvalue for each column\n",
    "l = []\n",
    "cols = list(data.columns)\n",
    "cols.remove('y')\n",
    "\n",
    "for col in cols:\n",
    "    if data[col].dtype == 'object':\n",
    "        cross_table = pd.crosstab(data[col], data['y'])\n",
    "        observed_values = cross_table.values\n",
    "        expected_values = chi2_contingency(observed_values)[3]\n",
    "        chi_square = sum([(o-e)**2/e for o, e in zip(observed_values,expected_values)])\n",
    "        chi_square_statistics = chi_square[0] + chi_square[1]\n",
    "        no_of_rows = observed_values.shape[0]\n",
    "        no_of_cols = observed_values.shape[1]\n",
    "        dof = (no_of_rows-1)*(no_of_cols-1)\n",
    "        alpha = 0.05\n",
    "        critical_value = chi2.ppf(q= 1-alpha, df=dof)\n",
    "        pvalue = 1 - chi2.cdf(x=chi_square_statistics, df=dof)\n",
    "        l.append({'Feature' : col, 'Pvalue' : pvalue})\n",
    "\n",
    "feature_pvalue = pd.DataFrame(l)\n",
    "print(feature_pvalue)\n",
    "\n",
    "#Since loan's pvalue is 0.2573652 i.e. > alpha or 0.05 we will drop that column \n",
    "data.drop(columns = ['loan'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5bb9c4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding\n",
    "col_list = []\n",
    "for col in data.columns:\n",
    "    if[(data[col].dtype=='object')&(col!='y')]:\n",
    "        col_list.append(col)\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    for i in col_list:\n",
    "        data[i] = le.fit_transform(data[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e79a17",
   "metadata": {},
   "source": [
    "Variance Inflation Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "87a0591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('poutcome', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "281490b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>1.249024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>job</td>\n",
       "      <td>2.056418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marital</td>\n",
       "      <td>4.223433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>education</td>\n",
       "      <td>3.976407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>default</td>\n",
       "      <td>1.302323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>housing</td>\n",
       "      <td>2.074821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>contact</td>\n",
       "      <td>2.043274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>month</td>\n",
       "      <td>4.158586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>day_of_week</td>\n",
       "      <td>2.836433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>duration</td>\n",
       "      <td>2.896304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>campaign</td>\n",
       "      <td>1.627395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>previous</td>\n",
       "      <td>1.231586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cons.conf.idx</td>\n",
       "      <td>4.056744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Features       VIF\n",
       "0             age  1.249024\n",
       "1             job  2.056418\n",
       "2         marital  4.223433\n",
       "3       education  3.976407\n",
       "4         default  1.302323\n",
       "5         housing  2.074821\n",
       "6         contact  2.043274\n",
       "7           month  4.158586\n",
       "8     day_of_week  2.836433\n",
       "9        duration  2.896304\n",
       "10       campaign  1.627395\n",
       "11       previous  1.231586\n",
       "12  cons.conf.idx  4.056744"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Multiconnearity : It refers to high correlation between two independent variables or predictors. \n",
    "#Example; Date of Birth and Age, both of this columns are example of multiconnearity, because any one is enough to know the age of a person. If we keep both columsn while train and test, the model's performance/accuracy willl be bad, because there shouldn't exist two variables high correlation.\n",
    "#We can find this multiconnearity using Variance Inflation Factor. We will check if certain independent column depdent on another independent column\n",
    "\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "col_list = []\n",
    "for col in data.columns:\n",
    "    if (data[col].dtype!='object') & (col!='y'):\n",
    "        col_list.append(col)\n",
    "\n",
    "    \n",
    "x = data[col_list]\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Features'] = x.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(x.values, i) for i in range(len(x.columns))]\n",
    "#We have a dataframe with columns with their respective VIF value. \n",
    "#Remember we need to drop all columns which has greater than 5 VIF value, as we drop one highest VIF column, the values changes for all columns.\n",
    "#If other columns' VIF value changes it means the other columns are negatively or positively correlated.\n",
    "#We need to drop one column at a time as the changes will applied after dropping one column\n",
    "vif_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8f81aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Model. Feature Engineering/Selection done, splitting x and y i.e. independent and dependent variable\n",
    "a = vif_data['Features']\n",
    "x = data[a]\n",
    "x\n",
    "\n",
    "y = data['y']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8719b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "76e4fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing and scaling the data, it helps the ML momdel to run efficiently and faster\n",
    "#Our data can be in different units and forms, so we need to standarize it.\n",
    "#scaling means making the data linear/uniform in units and making it easier for model to run faster and efficiently\n",
    "#Say, you have 214,155,1005151,201e-02, 2011, 241 and 0.2, 0.4, 0.5, 0.6, 0.7, the decimal values has uniformity while others nmbers don't, so scaling will just do that, make it uniform and make sure same units are there. \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4a7c1a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Building model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "32835960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting for x_test data\n",
    "y_pred = lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "497355b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6287,  474],\n",
       "       [  69,   97]], dtype=int64)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking TP, TN\n",
    "from sklearn.metrics import *\n",
    "confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d945440a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    31799\n",
       "1     2835\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if data is balanced\n",
    "data['y'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ba4e58ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9891441157960982\n",
      "0.9298920278065375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.6997683341404835"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding Recall, Precision, F-Beta because data is imbalanced, 1 is 2835 and 0 is 31799\n",
    "\n",
    "Recall = 6287/(6287+69) #TP/TP+FN\n",
    "print(Recall)\n",
    "\n",
    "Precision = 6287/(6287+474) #TP/TP+FP\n",
    "print(Precision)\n",
    "\n",
    "F_Beta = 2*Precision*Recall/1 * Precision + Recall # (1+B^2) * Precision * Recall/B^2 * Precision + Recall, we have taken B = 1, hence B^2 = 1\n",
    "F_Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "abee25b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9216110870506713"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you want to do with accuracy the formula is as below: **Remember the data is imbalanced data we don't find performance using accuracy metric.\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59f81b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
